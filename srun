#!/usr/bin/env bash
# ─────────────────────────────────────────────────────────────
#  srun — acquire GPUs from the scheduler, then exec your command
# ─────────────────────────────────────────────────────────────
set -euo pipefail

GPUSCHED_URL="${GPUSCHED_URL:-http://localhost:9123}"
SRUN_DIR="$(cd "$(dirname "$0")" && pwd)"

# ── colours ─────────────────────────────────────────────────
if [[ -t 1 ]]; then
  BOLD=$'\033[1m'  DIM=$'\033[2m'  RST=$'\033[0m'
  GRN=$'\033[32m'  YLW=$'\033[33m'  RED=$'\033[31m'
else
  BOLD="" DIM="" RST="" GRN="" YLW="" RED=""
fi

usage() {
  cat <<EOF
${BOLD}srun${RST} — acquire GPUs and run a command

${BOLD}Usage:${RST}
  srun [-n NUM_GPUS] command [args...]   Run a GPU job
  srun update                            Self-update (git pull)
  srun status                            Show scheduler status
  srun jobs                              List running jobs

${BOLD}Options:${RST}
  -n, --num-gpus N   Number of GPUs needed (default: 1)
  -h, --help         Show this help

${BOLD}Example:${RST}
  srun python train.py --epochs 50
  srun -n 2 torchrun --nproc_per_node=2 train.py

${DIM}Blocks until GPUs are available, then runs your command.${RST}
EOF
}

die() {
  echo "" >&2
  usage >&2
  echo "" >&2
  echo "${RED}error:${RST} $*" >&2
  exit 1
}

# ── subcommands ─────────────────────────────────────────────
case "${1:-}" in
  update)
    echo "${DIM}Updating local-gpu-scheduler...${RST}"
    git -C "$SRUN_DIR" pull
    echo "${GRN}✓ Updated${RST}"
    exit 0 ;;
  status)
    curl -sf --connect-timeout 2 --max-time 5 "${GPUSCHED_URL}/status" | python3 -m json.tool 2>/dev/null \
      || die "cannot reach scheduler at ${GPUSCHED_URL}"
    exit 0 ;;
  jobs)
    curl -sf --connect-timeout 2 --max-time 5 "${GPUSCHED_URL}/jobs" | python3 -m json.tool 2>/dev/null \
      || die "cannot reach scheduler at ${GPUSCHED_URL}"
    exit 0 ;;
  -h|--help)
    usage; exit 0 ;;
esac

# ── parse args ──────────────────────────────────────────────
ngpus=1
while [[ $# -gt 0 ]]; do
  case "$1" in
    -n|--num-gpus) ngpus="$2"; shift 2 ;;
    -h|--help) usage; exit 0 ;;
    -*) die "unknown option '$1'" ;;
    *) break ;;
  esac
done

[[ $# -eq 0 ]] && die "no command given"

command -v curl &>/dev/null || die "'curl' is required — install with: sudo apt-get install -y curl"
command -v jq   &>/dev/null || die "'jq' is required — install with: sudo apt-get install -y jq"

# ── request GPUs from scheduler ─────────────────────────────
pid=$$
echo "${DIM}srun: requesting ${ngpus} GPU(s) from scheduler (pid=${pid})...${RST}"

resp=$(curl -sf --connect-timeout 2 -X POST -H "Content-Type: application/json" \
  -d "{\"pid\":${pid},\"num_gpus\":${ngpus}}" \
  "${GPUSCHED_URL}/acquire" 2>/dev/null) \
  || die "cannot reach scheduler at ${GPUSCHED_URL} — is the server running?"

gpus=$(echo "$resp" | jq -r '.gpus')
job_id=$(echo "$resp" | jq -r '.job_id')

[[ "$gpus" == "null" || -z "$gpus" ]] && die "scheduler returned no GPUs"

CUDA_VISIBLE_DEVICES="$gpus"
echo "${GRN}srun: acquired GPU(s) ${BOLD}${CUDA_VISIBLE_DEVICES}${RST}${GRN} (job=${job_id})${RST}"
export CUDA_VISIBLE_DEVICES

# ── exec the user's command with assigned GPUs ──────────────
exec "$@"
